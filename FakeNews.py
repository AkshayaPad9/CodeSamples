# -*- coding: utf-8 -*-
"""Copy of 4740_FA20_p1_ak749_apr65.ipynb
Automatically generated by Colaboratory.
Original file is located at
    https://colab.research.google.com/drive/1kYgYu7n9apEHPS-LeiZfkvOrq1JbTGHb
# Project 1: Language Modeling and Fake News Classification
Created by Akshaya Raghavan and Aditi Kashyap
## Introduction
In this project we will build an **n-gram-based language model** for fake news classification. We will also investigate a feature-based **Naive Bayes model**. The task we are faced with is to **decide whether a news article is fake or real**. While some fake articles are so absurd and nonsensical that one can clearly guess they are fake, most fake news is actually quite hard to detect. [Various studies](https://pacscenter.stanford.edu/research/program-on-democracy-and-the-internet/deception-detection-accuracy-for-fake-news-headlines-on-social-media/) have shown that most people can have an error rate up to 50% depending on the theme of the article. 
To help us approach this problem, we will use NLP techniques covered thus far to frame this as a (supervised) binary classification task, where each article will have a label $y \in \{0,1\}$, where *0 indicates a fake article* and *1 indicates a real one*.
### Dataset
You are given a **News Corpus** on CMS, which consists of roughly the same amount of real and fake news articles.
Real news example:
```
The OpenAI technology, known as GPT-2, is designed to predict the next word given all the previous words it is shown within some text. The language-based model has been trained on a dataset of 8 million web pages.
```
Fake news example:
```
In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.
```
# Part 1: Preprocessing the Dataset
In this part, you are going to do a few things:
* Connect to the google drive where the data set is stored
* Load and read files
* Preprocess the text
## 1.1 Connect to google drive
"""

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

"""## 1.2 Load and read files
First, let's install [NLTK](https://www.nltk.org/), a very widely package for NLP preprocessing (and other tasks) for Python.
"""

!pip install -U nltk

import os
import io
from nltk import word_tokenize, sent_tokenize
import nltk
nltk.download('punkt')

root_path = os.path.join(os.getcwd(), "drive", "My Drive/Colab Notebooks") # replace based on your Google drive organization
dataset_path = os.path.join(root_path, "4740_p1_dataset") # same here

with io.open(os.path.join(dataset_path, "trueDataTrain.txt"), encoding='utf8') as real_file:
  real_news = real_file.read()
with io.open(os.path.join(dataset_path, "trueDataValidation.txt"), encoding='utf8') as real_file:
  real_news_validation = real_file.read()
with io.open(os.path.join(dataset_path, "fakeDataTrain.txt"), encoding='utf8') as fake_file:
  fake_news = fake_file.read()
with io.open(os.path.join(dataset_path, "fakeDataValidation.txt"), encoding='utf8') as real_file:
  fake_news_validation = real_file.read()

tokenized_real_news_training = [list(map(str.lower, word_tokenize(sent))) for sent in sent_tokenize(real_news)]
tokenized_fake_news_training = [list(map(str.lower, word_tokenize(sent))) for sent in sent_tokenize(fake_news)]
tokenized_real_news_validation = [list(map(str.lower, word_tokenize(sent))) for sent in sent_tokenize(real_news_validation)]
tokenized_fake_news_validation = [list(map(str.lower, word_tokenize(sent))) for sent in sent_tokenize(fake_news_validation)]

tokenized_real_news_training[0]

tokenized_fake_news_training[0]

"""## 1.3 Data Preprocessing & Preparation"""

# TODO: preprocessing
def clean_punct(tokenized_data):
  punctuation = "!\#$%&()*+,'\"’ “”-./:;<=>?@[\]^_`{|}~"
  clean_data = []
  for lst in tokenized_data:
    for token in lst:
      if token in punctuation:
        continue
      elif token.find("'")!=-1:
        clean_data.append(token[:token.find("'")])
      else:
        clean_data.append(token)
  return clean_data

clean_real_news_training = clean_punct(tokenized_real_news_training)
clean_fake_news_training = clean_punct(tokenized_fake_news_training)

# TODO: observations/statistics
#Finding the number of words in each article in both real and fake sets
# We are assuming that each article is an element of the list of training data

def count_words_per_article (tokenized_data):
  num_sentences = []
  for lst in tokenized_data:
    num_sentences.append(len(lst))
  return num_sentences

num_sentences_real_news = count_words_per_article(tokenized_real_news_training)
num_sentences_fake_news = count_words_per_article(tokenized_fake_news_training)

print("The number of words in each of the articles of the real training set is:")
print(num_sentences_real_news)
print("The number of words in each of the articles of the fake training set is:")
print(num_sentences_fake_news)

# TODO: observations/statistics
from nltk import collections
from collections import Counter
from nltk import ngrams

#Getting most frequent bigram from clean data - i.e. no punctuation
def most_frequent_bigrams(clean_data):
  bigrams = ngrams(clean_data, 2)
  fdist = nltk.FreqDist(bigrams)
  most_freq = fdist.most_common(20)
  return most_freq

#Getting most frequent words from clean data - i.e. no punctuation
def most_frequent_words(clean_data):
  word_counts = Counter(clean_data)
  most_freq = word_counts.most_common(20)
  return most_freq

print("The most frequent bigrams in real and fake news are:")
print(most_frequent_bigrams(clean_real_news_training))
print(most_frequent_bigrams(clean_fake_news_training))

print("The most frequent words are in real and fake news are:")
print(most_frequent_words(clean_real_news_training))
print(most_frequent_words(clean_fake_news_training))

#We see that a lot of the words we have are not useful in determining any context or difference between
# fake and real news, so we remove these stopwords
from nltk.corpus import stopwords
nltk.download("stopwords")
stopwords = stopwords.words('english')

def remove_stopwords(clean_data):
  clean_no_stop = []
  for word in clean_data:
    if word not in stopwords:
      clean_no_stop.append(word)
  return clean_no_stop

clean_no_stop_real = remove_stopwords(clean_real_news_training)
clean_no_stop_fake = remove_stopwords(clean_fake_news_training)

#We now rerun our analyses on most frequent words and bigrams

print("The most frequent bigrams in real and fake news are:")
print(most_frequent_bigrams(clean_no_stop_real))
print(most_frequent_bigrams(clean_no_stop_fake))

print("The most frequent words in real and fake news are:")
print(most_frequent_words(clean_no_stop_real))
print(most_frequent_words(clean_no_stop_fake))

"""# Part 2: Compute Unsmoothed Language Models.
## 2.1 Unsmoothed Uni-gram Model.
"""

"""
Function [count_words] computes the number of times a token appears
in a dataset
lst: a list of words in a sentence
Return: [dictionary] that stores the result
Import counter
"""
from collections import Counter
def count_words(lst):
  return dict(Counter(lst))

"""
Function [unsmoothed_unigram] computes the probabilities for a unigram model
lst: a list of words in a sentence
Return: [dictionary] that stores the result
"""

def unsmoothed_unigram(lst):
  # TODO
  total_count = len(lst)*1.
  total_probabilities = {}
  word_count = count_words(lst)
  for word in word_count:
    total_probabilities[word] = word_count[word] / total_count
  return total_probabilities

count_words(clean_no_stop_fake)

dict_unsmoothed_unigram_real = unsmoothed_unigram(clean_no_stop_real)
dict_unsmoothed_unigram_fake = unsmoothed_unigram(clean_no_stop_fake)
print(dict_unsmoothed_unigram_real)

"""## 2.2 Unsmoothed Bi-gram Model.
In this part of the project, you are trying to compute the probabilities for a bigram model. You can approach this with similar methods as above.
Remember the definition:
$p(w_n\mid w_{n-1})=\frac{C(w_{n-1}w_n)}{C(w_{n-1})}$ this means you might want to store two things (count of $w_{n-1}$ and count of $w_{n-1}w_n$).
"""

# TODO: Add code for bigram probability calculation. 

def bicount_words(lst):
  modified_lst = [lst[i - 1] + " " + lst[i] for i in range (1,len(lst))]
  return dict(Counter(modified_lst))
  
def unsmoothed_bigram(lst):
  total_probabilities={}
  count_bigram=bicount_words(lst)
  count_unigram = count_words(lst)
  for words in count_bigram:
    total_probabilities[words]=count_bigram[words]/count_unigram[words.split(" ")[0]]
  return total_probabilities

dict_unsmoothed_bigram_real = unsmoothed_bigram(clean_no_stop_real)
dict_unsmoothed_bigram_fake = unsmoothed_bigram(clean_no_stop_fake)
print(len(bicount_words(clean_no_stop_real)))
print(len(clean_no_stop_real))

"""# Part 3: Smoothed Language Model"""

# TODO: Add your unknown word handling code 
import random

def create_unknown_word_list(lst):
  modified_list = []
  vocabulary=set()
  for token in lst:
    if token in vocabulary:
      modified_list.append(token)
    else:
      r = random.randint(1,101)
      if (r<30):
        modified_list.append("<UNK>")
      else:
        modified_list.append(token)
      vocabulary.add(token)
  return modified_list,vocabulary
clean_training_set = clean_no_stop_real + clean_no_stop_fake
clean_unk_training,vocabulary = create_unknown_word_list(clean_training_set)
clean_unk_real_training = clean_unk_training[0:len(clean_no_stop_real)]
clean_unk_fake_training = clean_unk_training[(len(clean_no_stop_real)+1):]
def unk_validation (tokenized_data):
  modified_validation_lst = []
  for lst in tokenized_data:
    for token in lst:
      if token in vocabulary:
        modified_validation_lst.append(token)
      else:
        modified_validation_lst.append("<UNK>")
  return modified_validation_lst
clean_unk_real_validation = unk_validation(tokenized_real_news_validation)
clean_unk_fake_validation = unk_validation(tokenized_fake_news_validation)

"""## 3.2 Smoothing
In this part of project, we are going to compute the probabilities for unigram and bigram models after smoothing.
There are several smoothing methods you can start with:
* add-k
* Kneser-Ney
* Good-Turing
* ...
You need to compute for both unigram and bigram models.
Below is a starter point using add-k smoothing. As always, you DO NOT need to follow it; you DO NOT need to use add-k smoothing if you do not want to. You can pick ANY smoothing method you want.
"""

from collections import Counter
def count_num_seen(count_word):
  count = Counter(count_word.values())
  return count

"""
Reference code for Good Turing smoothing on unigram model.
dicCount: a count of each unique word within the preprocessed corpus
lst: preprocessed tokens
Return: a dictionary of probability results after smoothing
"""
def good_turing_unigram(count_word,lst):
  turing_probabilities = {}
  total_count = len(lst)*1.
  number_unigrams_per_occurance = count_num_seen(count_word)
  for word in count_word:
    current_count = count_word[word]
    if number_unigrams_per_occurance[current_count+1]!=0:
      modified_count = (current_count +1)*number_unigrams_per_occurance[current_count] / number_unigrams_per_occurance[current_count+1]
    else:
      modified_count = current_count
    turing_probabilities[word] = modified_count/total_count
  return turing_probabilities

dict_smoothed_unigram_real = good_turing_unigram(count_words(clean_unk_real_training),clean_unk_real_training)
dict_smoothed_unigram_fake = good_turing_unigram(count_words(clean_unk_fake_training),clean_unk_fake_training)



"""
bi_dic: a dictionary of bigram probabilities
bidicCount: count of unique bigrams within preprocessed corpus
Return: a dictionary of probability results after smoothing
"""
def good_turing_bigram(count_unigram,count_word, unsmooth_bigram_dic):
  turing_probabilities = {}
  number_bigrams_per_occurance = count_num_seen(count_word)
  for word in count_word:
    current_count = count_word[word]
    if number_bigrams_per_occurance[current_count+1]!=0:
      modified_count = (current_count +1)*number_bigrams_per_occurance[current_count] / number_bigrams_per_occurance[current_count+1]
    else:
      modified_count = current_count
    turing_probabilities[word] = modified_count/count_unigram[word.split(" ")[0]]
  return turing_probabilities

# To create the dictionary of word counts to pass in for the smoothing methods, 
# use the previously defined function [count_words]

dict_smoothed_bigram_real = good_turing_bigram(dict_smoothed_unigram_real,bicount_words(clean_unk_real_training),dict_unsmoothed_bigram_real)
dict_smoothed_bigram_fake = good_turing_bigram(dict_smoothed_unigram_fake,bicount_words(clean_unk_fake_training),dict_unsmoothed_bigram_fake )

dict_unsmoothed_bigram_real_fake = unsmoothed_bigram(clean_no_stop_fake)

"""# Part 4: Perplexity
At this point, we have developed several language models: unigram vs bigram, unsmoothed vs smoothed. We now want to compare all the models.
## Task 1: Compute perplexity for smoothed unigram and smoothed bigram.
"""

# TODO: compute perplexity for one smoothing method on unigram, and one smoothing method on bigram.

#These methods work for both unigram and bigram models, requiring that the correct
#dictionary is put in

"""
dict: a dictionary of either unigram or bigram probabilities
num: length of the tokenized list of data
Returns: the inner calculation for perplexity
"""
import math
def sum_probability(lst):
  sumProbability=0
  for prob in lst:
    sumProbability-=math.log(prob)
  return sumProbability

"""
sum: the inner calculation for perplexity
num: length of the tokenized list of data
Returns: perplexity of the model
"""
def calc_perplexity(sum, num):
  return math.exp(1/num*sum)

def calcProbabilityBigramValidation(test_data,bigram_model):
  validation_bigram_probabilities=[]
  lst_of_bigrams = [test_data[i - 1] + " " + test_data[i] for i in range (1,len(test_data))]
  for bigram_words in lst_of_bigrams:
    bigram = bigram_model.get(bigram_words,0)
    if (bigram==0):
      continue
    else:
      validation_bigram_probabilities.append(bigram)
  return validation_bigram_probabilities

new_real_validation = clean_punct(tokenized_real_news_validation)

real_validation_without_stop = remove_stopwords(new_real_validation)

new_fake_validation = clean_punct(tokenized_fake_news_validation)

fake_validation_without_stop = remove_stopwords(new_fake_validation)

real_validation_with_unk=[]
for words in real_validation_without_stop:
  for word in words:
    if word in vocabulary:
      real_validation_with_unk.append(word)
    else:
      real_validation_with_unk.append("<UNK>")

fake_validation_with_unk=[]
for words in tokenized_fake_news_validation:
  for word in words:
    if word in vocabulary:
      fake_validation_with_unk.append(word)
    else:
      fake_validation_with_unk.append("<UNK>")

prob_validation_real = calcProbabilityBigramValidation(real_validation_with_unk,dict_smoothed_bigram_real)

prob_validation_fake = calcProbabilityBigramValidation(fake_validation_with_unk,dict_smoothed_bigram_fake)

sum_bigram_real = sum_probability(prob_validation_real)
perp_bigram_real = calc_perplexity(sum_bigram_real,len(tokenized_real_news_validation))
print(perp_bigram_real)

sum_bigram_fake = sum_probability(prob_validation_fake)
perp_bigram_fake = calc_perplexity(sum_bigram_fake,len(tokenized_fake_news_validation))
print(perp_bigram_fake)

#returns probability of test data
def calcProbabilityBigram(article,bigram_model):
  total_final_probability = 0
  lst_of_bigrams = [article[i - 1] + " " + article[i] for i in range (1,len(article))]
  for bigram_words in lst_of_bigrams:
    bigram = bigram_model.get(bigram_words,0)
    if (bigram!=0):
      total_final_probability += math.log(bigram)
    else:
      total_final_probability+=bigram
  return total_final_probability

import math
with io.open(os.path.join(dataset_path, "TestData.txt"), encoding='utf8') as real_file:
  test_news = real_file.read()

test_list = test_news.split("\n")
lst_probability_articles=[]
for article in test_list:
  tokenized_article = [list(map(str.lower, word_tokenize(sent))) for sent in sent_tokenize(article)]
  new_article = clean_punct(tokenized_article)
  article_without_stop = remove_stopwords(new_article)
  article_with_unk = []
  for word in article_without_stop:
    if word in vocabulary:
      article_with_unk.append(word)
    else:
      article_with_unk.append("<UNK>")  
  prob_real = calcProbabilityBigram(article_with_unk,dict_smoothed_bigram_real)
  prob_fake = calcProbabilityBigram(article_with_unk, dict_smoothed_bigram_fake)
  if (prob_fake>prob_real):
    lst_probability_articles.append(0)
  else:
    lst_probability_articles.append(1)

# TODO: Add code to generate the Kaggle output file and submit the output file to Kaggle

with open(os.path.join(dataset_path, "Submission.csv"), 'w') as fp :
  fp.write("Id,Prediction\n")
  for id,prediction in enumerate(lst_probability_articles):
    fp.write(f"{id},{prediction}\n")



"""# Part 6: Naive Bayes
## 6.1 Implementation
"""

# TODO: Naive Bayes implementation 
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB

combined_clean_data = clean_unk_real_training + clean_unk_fake_training
target_vals_real = [0] * len(clean_unk_real_training)
target_vals_fake = [1] * len(clean_unk_fake_training)
target_vals = target_vals_real + target_vals_fake
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(combined_clean_data)
print(len(combined_clean_data))
clf=MultinomialNB()
result = clf.fit(X,target_vals)

"""## 6.2 Putting Everything Together and Submitting to Kaggle
You should use your trained model to predict labels for all the news in `TestData.txt`. Output your predictions to a **csv** file and submit it to kaggle. The format should follow Part 6 as well.
Use this Kaggle [link](https://www.kaggle.com/t/e8e4f7ee507843d1902c168529d705c8) to submit your output.
"""

# TODO: Code for predicting the test labels and generating the output file. Then submit the output file to Kaggle
with io.open(os.path.join(dataset_path, "TestData.txt"), encoding='utf8') as real_file:
  results=[]
  test_news = real_file.read()
  test_list = test_news.split("\n")
  X2 = vectorizer.transform(test_list)
  results=result.predict(X2)
  with open(os.path.join(dataset_path, "Submission2.csv"), 'w') as fp :
    fp.write("Id,Prediction\n")
    for id,prediction in enumerate(results):
      fp.write(f"{id},{prediction}\n")
